########################
#docker, docker-compse설치
########################

## Docker 


sudo yum remove docker \
                  docker-common \
                  docker-selinux \
                  docker-engine

sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2

sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo

sudo yum-config-manager --enable docker-ce-edge

sudo yum install -y docker-ce

sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

sudo chmod +x /usr/local/bin/docker-compose

########################
#elasticsearch설치
########################

폴더를 만들고 파일명을 디폴트인 docker-compose.yaml로 만든다
그런 다음 그 디렉토리 안에서 데몬으로 실행하고
docker-compose up -d

로그를 보면서 정상구동 되는지 확인한다
docker-compose logs -f

ctrl+c로 로그 보는 것을 마치고 구동상태 확인 (물론 docker ps로도 확인 가능)
docker-compose ps

크롬 헤드 확장프로그램에서 접속테스트

서비스종료 후 삭제
docker-compose stop
docker-compose rm 


version: '2.2'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.1.1
    container_name: elasticsearch
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata1:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - esnet
  elasticsearch2:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.1.1
    container_name: elasticsearch2
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "discovery.zen.ping.unicast.hosts=elasticsearch"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata2:/usr/share/elasticsearch/data
    networks:
      - esnet

volumes:
  esdata1:
    driver: local
  esdata2:
    driver: local

networks:
  esnet:


########################
#kibana설치
########################


mkdir /root/es-kibana
vi /root/es-kibana/docker-compose.yaml
----------------------------------------------------
version: '2'
services:
  kibana:
    image: docker.elastic.co/kibana/kibana:6.1.1
    environment:
      SERVER_NAME: kibana.example.org
      ELASTICSEARCH_URL: http://10.10.64.65:9200
    ports:
      - 5601:5601
    networks:
      - esnet
networks:
  esnet:
----------------------------------------------------

docker-compose up -d




########################
#LOGSTASH설치
########################

docker run --name logstash01 -dit centos /bin/sh

docker exec -it logstash01 /bin/sh

yum install -y wget
yum install -y unzip

cd /opt/

wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz"

tar xzf jdk-8u131-linux-x64.tar.gz
cd /opt/jdk1.8.0_131/

alternatives --install /usr/bin/java java /opt/jdk1.8.0_131/bin/java 2

alternatives --config java

clear
java -version
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin


#MSSQL JDBC
cd ~
wget http://10.10.63.63:8089/sqljdbc_6.0.8112.100_kor.tar.gz
tar xvf sqljdbc_6.0.8112.100_kor.tar.gz
ls /root/sqljdbc_6.0/kor/jre8





cat << EOF >> /root/.bash_profile
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin
EOF




mkdir -p /app
cd /app
wget  http://10.10.63.63:8089/logstash-6.1.1.zip


unzip logstash-6.1.1.zip

cd /app/logstash-6.1.1/bin

#Case1. 대화형 IN/OUT

vi logstash.conf
----------------------------------------------------------
input { stdin { } }
output {
  elasticsearch { hosts => ["x.x.x.x:9200"] }
  stdout { codec => rubydebug }
}
----------------------------------------------------------

cd /app/logstash-6.1.1/bin

./logstash -f logstash.conf

#Case2. MSSQL 테스트 & 기초데이터(Win32_OS)

vi logstash-mssql-test.conf
--------------------------------------------------------------------------------------------------------------------------------------------
input {
jdbc {
jdbc_driver_library => "/root/sqljdbc_6.0/kor/jre8/sqljdbc42.jar"
jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
jdbc_connection_string => "jdbc:sqlserver://10.10.63.63:1433"
jdbc_user => "kibana_systemcenter"
  jdbc_password => "P@ssw5rd"
statement => "select os_name, os_desc, os_installed from tbl_win32_os"
  }
}

output {
  elasticsearch {
  "hosts" => ["10.10.64.65:9200"]
  "index" => "win32-os"
"document_type" => "data"
}
  stdout { codec => rubydebug }
}
--------------------------------------------------------------------------------------------------------------------------------------------

./logstash -f logstash-mssql-test.conf




#Case2. MSSQL 테스트 & 기초데이터(Subway)

#Chrome kibana console
PUT /subway_in

PUT subway_in/_mapping/dataforcustomer
{"properties": 
{
"@timestamp": { "type": "date", "format": "strict_date_optional_time||epoch_millis" },
"@version": { "type": "text" },
"mydate": { "type": "date" },
"id":{ "type": "integer" },
"cnt":{ "type": "integer" },
"xpoint_wgs" : { "type": "float" },
"ypoint_wgs" : { "type": "float" },
"station_nm" : { "type": "keyword" }, 
"line_num":{ "type": "integer" },
"location": { "type": "geo_point" }
}
}




cd /app/logstash-6.1.1/bin

vi  logstash-mssql-subway.conf
--------------------------------------------------------------------------------------------------------------------------------------------
input {
jdbc {
jdbc_driver_library => "/root/sqljdbc_6.0/kor/jre8/sqljdbc42.jar"
jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
jdbc_connection_string => "jdbc:sqlserver://10.10.63.63:1433"
jdbc_user => "kibana_systemcenter"
jdbc_password => "P@ssw5rd"
statement => "select * from subway_in_geo"
jdbc_paging_enabled => "true"
jdbc_page_size => "50000"
}
}
filter {
mutate {
add_field => { "[location][lat]" => [ "%{xpoint_wgs}" ] }
add_field => { "[location][lon]" => [ "%{ypoint_wgs}" ] }
convert => [ "[location]", "float" ]
}
}
output {
elasticsearch {
hosts => "X.X.X.X:9200"
index => "subway_in"
#document_id => "%{id}"
document_type => "dataforcustomer"
manage_template => true
}
#stdout { codec => rubydebug }
}
--------------------------------------------------------------------------------------------------------------------------------------------

./logstash -f logstash-mssql-subway.conf





