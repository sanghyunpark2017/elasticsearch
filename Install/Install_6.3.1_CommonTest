
################################
2018/07/10
ElasticSearch 6.3.1
################################

10.10.64.91 t1velastic1
10.10.64.92 t1velastic2
10.10.64.93 t1velastic3

discovery.zen.mininum_master_nodes : (3 / 2) + 1 = 2


#SWAP Off
sysctl -w vm.swappiness=0
vi /etc/fstab

shutdown -r now

#방화벽설정
systemctl enable firewalld
systemctl start firewalld
firewall-cmd --permanent --add-port=9200-9400/tcp
firewall-cmd --permanent --add-port=9600-9700/tcp
firewall-cmd --permanent --add-port=5601/tcp
firewall-cmd --permanent --add-port=5555/tcp
firewall-cmd --reload   

firewall-cmd --list-all

#################################
JAVA설치
#################################

yum install -y wget
cd /opt/

wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz"

tar xzf jdk-8u131-linux-x64.tar.gz
cd /opt/jdk1.8.0_131/
alternatives --install /usr/bin/java java /opt/jdk1.8.0_131/bin/java 2

alternatives --config java

clear
java -version
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin

cat << EOF >> /root/.bash_profile
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin
EOF

#################################
Install elasticsearch 6.3.1
#################################
#데이터 (path.data) : /var/lib/elasticsearch
#로그 (path.logs) : /var/log/elasticsearch

cd ~
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.1.rpm

sudo rpm --install elasticsearch-6.3.1.rpm

grep "elasticsearch" /etc/passwd
grep "elasticsearch" /etc/group 

sudo systemctl daemon-reload
sudo systemctl enable elasticsearch.service

#elasticsearch.yml 파일 백업
cd /etc/elasticsearch
cp elasticsearch.yml elasticsearch.yml.org

#elasticsearch.yml 새로 생성
cat << EOF > /etc/elasticsearch/elasticsearch.yml
cluster.name: hmp-sds-logs
node.name: ${HOSTNAME}
network.host: 0.0.0.0
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-headers: Authorization       #for head & XPACK
transport.tcp.port: 9300 
node.master: true
node.data: true
node.ingest: true
path.data: /app/elasticsearch/data
path.logs: /app/elasticsearch/log
#index.number_of_shards: 5
#index.number_of_replicas: 1
discovery.zen.ping_timeout: 10s
discovery.zen.ping.unicast.hosts: ["10.10.64.91:9300", "10.10.64.92:9300",  "10.10.64.93:9300"]
#discovery.zen.minimum_master_nodes: 3  #for 5 nodes 
discovery.zen.minimum_master_nodes: 2  #for 3 nodes 
#action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*,.ml*
EOF

#디렉토리 생성
mkdir -p /app/elasticsearch/data
mkdir -p /app/elasticsearch/log
chown elasticsearch:elasticsearch -R /app/elasticsearch


#서비스 실행
sudo systemctl start elasticsearch.service
sudo systemctl status elasticsearch.service


#크롬 elasticsearch head 설치 후 접속
http://10.10.64.91:9200

#################################
패러미터 조정 
#################################

#java heap은 전체 메모리의 50%로 지정. 나머지 50%는 루씬 파일 캐시에 사용.
vi /etc/elasticsearch/jvm.options
-Xms1g
-Xmx1g

#파일
cat << EOF >> /etc/security/limits.conf
elasticsearch soft memlock unlimited
elasticsearch hard memlock unlimited
EOF

#Install Elasticsearch X-Pack (PASS)
#6.3.1 버전은 X-Pack이 기본으로 설치되어 있음

##################################################################
Install KIBANA 6.x & X-PACK (1번 마스터서버)
##################################################################

#모든서버 서비스 중지
systemctl stop elasticsearch

#1번 마스터에 설치
rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

cat << EOF > /etc/yum.repos.d/kibana.repo
[kibana-6.x]
name=Kibana repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF


#kibana 최신버전(6.3.1) 설치 - 2018/07/09
sudo yum install -y kibana 

sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable kibana.service


#kibana.yml 기본파일 백업 후 설정
#TCP 5601를 모든 IP에서 Listen하게 한다. 127.0.0.1 -> 0.0.0.0
cd /etc/kibana/kibana.yml
cp kibana.yml kibana.yml.org

cat << EOF > /etc/kibana/kibana.yml
server.host: 0.0.0.0
elasticsearch.url: http://10.10.64.91:9200
EOF

#모든서버에 elasticsearch  서비스 시작
systemctl start elasticsearch
systemctl status elasticsearch


#마스터서버에 kibana 서비스 시작(처음 기동 떄는 포트리슨까지 수십 초 걸림)
systemctl start kibana
systemctl status kibana


#로그확인
journalctl -u kibana.service

#마스터서버 kibana접속
http://10.10.64.91:5601











#################################
데이터 초기백업
#################################

#데이터노드백업
systemctl stop kibana
systemctl stop elasticsearch

cd ~
tar cvfzp elastic_data_initial.tar.gz /app/elasticsearch/data/nodes/

systemctl start elasticsearch
systemctl start kibana


#################################
데이터 복구
#################################

#모든 노드 서비스 중지
systemctl stop kibana
systemctl stop elasticsearch

rm -rf /var/lib/elasticsearch/nodes
mkdir -p /var/lib/elasticsearch/nodes
chown elasticsearch:elasticsearch /var/lib/elasticsearch/nodes

cd /
tar xvfzp /root/elastic_data_initial.tar.gz 

systemctl start elasticsearch
systemctl start kibana




#################################
1번 마스터서버에서 로그삭제 스케쥴
################################

#crontab 
---------------------------------------------------
###elasticsearch
59 23 * * * /root/mycron/delete_logs.sh
---------------------------------------------------

#srcripts
mkdir -p /root/mycron

vi /root/mycron/delete_logs.sh
---------------------------------------------------
#!/bin/sh

curl -XDELETE http://localhost:9200/logstash-20*
echo `date` : Delete logstash logs  >> /root/mycron/elastic_history.log
---------------------------------------------------


#################################
마스터서버에 LOG STASH 설치
################################

#모든서버에 설치
rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

cat << EOF > /etc/yum.repos.d/logstash.repo 
[logstash-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

sudo yum install -y logstash

#설정변경
cat << EOF >> /etc/logstash/logstash.yml
http.host "0.0.0.0"
http.port: 9600-9700
EOF



################################################################
LOG STASH 입력테스트1(화면입력)
################################################################

#화면 입력 테스트용 설정파일 작성 (3대 각각 확인)
cat << EOF > /root/test1.conf
input { stdin { } }
output {
  elasticsearch { hosts => ["localhost:9200"] }
  stdout { codec => rubydebug }
}
EOF

#화면 입력 테스트
#-서버 1대씩 롤링 테스트
#-head에서 입력 확인

curl -XDELETE http://localhost:9200/logstash*
/usr/share/logstash/bin/logstash --path.settings=/etc/logstash  -f /root/test.conf



################################################################
LOG STASH 입력테스트2(멀티라인파일입력)
################################################################


#멀티라인 파일 입력 테스트용 설정파일 작성 (3대 각각 확인)
cat << EOF > /root/test2.conf
input {
  file {
    path => "/root/test2.log"
    start_position => "beginning"
    stat_interval => 10
    codec => multiline {
      pattern => "^\s"
      what => "previous"
    }
  }
}

output {
  elasticsearch { hosts => "http://10.10.62.103:9200"
  index => "test2-log"
  }
  stdout { codec => rubydebug }
}
EOF

#멀티라인 테스트용 파일 작성

cat << EOF > /root/test2.log
2018-07-09 01:00:00 row1
  row1-1
  row1-2
  row1-3
2018-07-09 02:00:00 row2
  row2-1
  row2-2
  row2-3
2018-07-09 03:00:00 row3
  row3-1
  row3-2
  row3-3
EOF

#실행(3대 롤링으로 테스트)

/usr/share/logstash/bin/logstash --path.settings=/etc/logstash -f /root/test2.conf

#head에서 확인 후 인덱스 삭제

curl -XDELETE http://localhost:9200/test2*

rm -f /root/test*


################################################################
LOG STASH 입력테스트3(logstash listen & filebeat 전송)
################################################################

#멀티라인 설정은 logstash와 filebeat가 다름
#logstash는 리슨만하고, 멀티라인 처리는 filebeat가 수행


##########################
#PART1. Logstash Listen&config
##########################

vi /root/logstash-pipeline-5555.conf
-----------------------------------------------------------
input { 
  beats { 
    port => "5555" 
  } 
} 
output {
  elasticsearch { hosts => "http://10.10.62.103:9200"
  index => "filebeat-test-log"
  }
}
-----------------------------------------------------------

#실행
/usr/share/logstash/bin/logstash -f /root/logstash-pipeline-5555.conf --config.reload.automatic

#--path.settings=/etc/logstash 

##########################
#PART2. Filebeat 설치/실행
##########################

#ElasticSecarch서버가 아닌 다른 서버에서 설치&테스트 (권장)
#10.10.64.66 테스트 서버 사용

#설치
rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch

vi /etc/yum.repos.d/elastic.repo
---------------------------------------------------------------
[elastic-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
---------------------------------------------------------------

yum install -y filebeat

#부팅 시 자동실행 설정
sudo chkconfig --add filebeat

cd /etc/filebeat
cp filebeat.yml filebeat.yml.org


#테스트파일 생성
cat << EOF > /root/test2.log
2018-07-09 01:00:00 row1
  row1-1
  row1-2
  row1-3
2018-07-09 02:00:00 row2
  row2-1
  row2-2
  row2-3
2018-07-09 03:00:00 row3
  row3-1
  row3-2
  row3-3
EOF

#테스트설정
vi /root/filebeat-test.conf
------------------------------------------------------
filebeat.prospectors:
- input_type: log
  paths:
    - /root/test2.log 
  multiline.pattern: '^[[0-9]{4}-[0-9]{2}-[0-9]{2}'
  multiline.negate: true
  multiline.match: after
output.logstash:
  hosts: ["10.10.62.103:5555"]
------------------------------------------------------

#운영설정

vi /root/filebeat-test.conf
------------------------------------------------------
filebeat:
  prospectors:
  - document_type: log
    encoding: utf-8
    input_type: log
    ignore_older: 24h
    scan_frequency: 5s
    clean_inactive: 48h  
    clean_removed: true    
    paths:
      - /root/test2.log 
    multiline.pattern: '^[[0-9]{4}-[0-9]{2}-[0-9]{2}'
    multiline.negate: true
    multiline.match: after
    multiline.timeout: 5s    
output.logstash:
  hosts:
  - 10.10.62.102:5555
  - 10.10.62.103:5555
  - 10.10.62.104:5555
  loadbalance: true
------------------------------------------------------

# -e 옵션은 디버그
/usr/share/filebeat/bin/filebeat -e -c /root/filebeat-test.conf   -d "publish"

curl -XDELETE http://localhost:9200/filebeat-test*



#테스트파일 재생성

cat << EOF > /root/test2.log
2018-07-09 01:00:00 row1
  row1-1
  row1-2
  row1-3
2018-07-09 02:00:00 row2
  row2-1
  row2-2
  row2-3
2018-07-09 03:00:00 row3
  row3-1
  row3-2
  row3-3
EOF

#테스트파일 라인추가(row4)
cat << EOF >> /root/test2.log
2018-07-09 04:00:00 row4
  row4-1
  row4-2
  row4-3
EOF

#테스트파일 라인추가(row5, row6)
cat << EOF >> /root/test2.log
2018-07-09 05:00:00 row5
  row5-1
  row5-2
  row5-3
EOF

cat << EOF >> /root/test2.log
  row6-1
  row6-2
  row6-3    
EOF


Notice!!!
파일순환 조건이 뭔지 inode가 바뀌는 건지 등 확인 필요함




#노트!!!!
VI편집기로 열어서 라인추가하고 저장하면 처음부터 모두 다시 로딩함
단, cat 으로 추가하면 라인 단위로 가져옴;;
-> cat 등은 inode가 바뀌지 않음
-> vi는 inode를 바꿈


more /usr/share/filebeat/bin/data/registry

