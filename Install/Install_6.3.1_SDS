

#버전 6.3.1은 elasticsearch x-pack과 kibana x-pack이 기본적으로 포함되어 있음
#이전 설치가이드와 다른 점은 x-pack 설치만 생략되어있음
#X-Pack Basic License의 기능을 만료 기한 없이 자유롭게 이용할 수 있음.
#logstash를 elasticsearch 서버와 같이 구동할 떄 메모리는 5GB 이상이어야 함 (OS 2GB, Elk 2GB, Logstash 1GB)
#메모리가 4GB 일 때는 메모리 부족으로 logstash systemd 에러가 나면서 서비스 등록이 안될 수도 있음 (대개 오류 발생)

#################################
대상서버
#################################

1번호스트 : master, data, ingest, kibana
2번호스트 : master, data, ingest, logstash
3번호스트 : master, data, ingest

discovery.zen.mininum_master_nodes : (3 / 2) + 1 = 2

#################################
OS BASIC
#################################

cd ~
cat << EOF >> .bashrc
export LS_COLORS="di=00;36:fi=00;37"
EOF

yum install -y net-tools

#################################
SWAP Off 및 방화벽설정
#################################
#TCP 5555 : logstash 리슨포트로 사용
#TCP 9600-9700 : 노드간 통신포트

sysctl -w vm.swappiness=0

systemctl enable firewalld
systemctl start firewalld
firewall-cmd --permanent --add-port=9200-9400/tcp
firewall-cmd --permanent --add-port=9600-9700/tcp
firewall-cmd --permanent --add-port=5601/tcp
firewall-cmd --permanent --add-port=5555/tcp
firewall-cmd --reload   

firewall-cmd --list-all

#서버방화벽 : 위와 같이 오픈
#네트웍방화벽 : 9200, 9300, 5555(로그스태쉬 사용할 것)



#################################
JAVA설치
#################################

yum install -y wget
cd /opt/

wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz"

tar xzf jdk-8u131-linux-x64.tar.gz
cd /opt/jdk1.8.0_131/
alternatives --install /usr/bin/java java /opt/jdk1.8.0_131/bin/java 2

alternatives --config java

clear
java -version
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin

cat << EOF >> /root/.bash_profile
export JAVA_HOME=/opt/jdk1.8.0_131
export JRE_HOME=/opt/jdk1.8.0_131/jre
export PATH=$PATH:/opt/jdk1.8.0_131/bin:/opt/jdk1.8.0_131/jre/bin
EOF

#################################
Install elasticsearch 6.3.1
#################################

기본 프로그램 ($ES_HOME) : /usr/share/elasticsearch
실행 파일 : bin/elasticsearch
플러그인 : plugins
설정 : /etc/elasticsearch
./elasticsearch.yml
./jvm.options
./log4j2.properties
데이터 (path.data) : /var/lib/elasticsearch
로그 (path.logs) : /var/log/elasticsearch

#################################
All servers
#################################

cd ~
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.1.rpm

sudo rpm --install elasticsearch-6.3.1.rpm

grep "elasticsearch" /etc/passwd
grep "elasticsearch" /etc/group 

sudo systemctl daemon-reload
sudo systemctl enable elasticsearch.service

#path.dat와 path.logs는 주석처리 한다
cd /etc/elasticsearch
cp elasticsearch.yml elasticsearch.yml.org

vi /etc/elasticsearch/elasticsearch.yml
-----------------------------------------------------------------------------------
#path.data: /var/lib/elasticsearch
#path.logs: /var/log/elasticsearch
-----------------------------------------------------------------------------------


cat << EOF >> /etc/elasticsearch/elasticsearch.yml
cluster.name: hmp-sds-logs
node.name: ${HOSTNAME}
network.host: 0.0.0.0
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-headers: Authorization       #for head & XPACK
transport.tcp.port: 9300 
node.master: true
node.data: true
node.ingest: true
path.data: /app/elasticsearch/data
path.logs: /app/elasticsearch/log
#index.number_of_shards: 5
#index.number_of_replicas: 1
discovery.zen.ping_timeout: 10s
discovery.zen.ping.unicast.hosts: ["10.10.62.102:9300", "10.10.62.103:9300",  "10.10.62.104:9300"]
#discovery.zen.minimum_master_nodes: 3  #for 5 nodes 
discovery.zen.minimum_master_nodes: 2  #for 3 nodes 
#action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*,.ml*
EOF

#확인
vi /etc/elasticsearch/elasticsearch.yml

#action.auto_create_index 항목은 xpack 설치 후 쓰는 것이며, 지금은 오류가 발생하니 주석처리해 둔다

#디렉토리 생성
mkdir -p /app/elasticsearch/data
mkdir -p /app/elasticsearch/log
chown elasticsearch:elasticsearch -R /app/elasticsearch

#마스터/노드 모든 서버에 서비스를 기동하고 크롬 헤드에서 정상 확인
sudo systemctl start elasticsearch.service
sudo systemctl status elasticsearch.service


#크롬일레스틱헤드에서 설치 확인
#크롬검색> chrome elasticsearch head 검색 후 설치
http://10.10.62.102:9200

#################################
패러미터 조정 
#################################

#java heap
#전체 메모리의 50%는 java heap, 나머지 50%는 루씬 파일 캐시에 사용

vi /etc/elasticsearch/jvm.options
-Xms2g
-Xmx2g

#swap off
swapoff -a

#파일
cat << EOF >> /etc/security/limits.conf
elasticsearch soft memlock unlimited
elasticsearch hard memlock unlimited
EOF


##################################################################
Install Elasticsearch X-Pack (PASS)
##################################################################
#6.3.1 버전은 X-Pack이 기본으로 설치되어 있음

##################################################################
1번 서버에 Install KIBANA 6.x & X-PACK
##################################################################

#모든서버 서비스 중지
systemctl stop elasticsearch

#1번 마스터에 설치
rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

cat << EOF > /etc/yum.repos.d/kibana.repo
[kibana-6.x]
name=Kibana repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

#kibana 최신버전(6.3.1) 설치 - 2018/07/09
sudo yum install -y kibana 

sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable kibana.service


#TCP 5601를 모든 IP에서 Listen하게 한다. (127.0.0.1 -> 0.0.0.0)
cat << EOF >> /etc/kibana/kibana.yml
server.host: 0.0.0.0
elasticsearch.url: http://10.10.62.102:9200
EOF

#모든서버에 elasticsearch  서비스 시작
systemctl start elasticsearch
systemctl status elasticsearch

#마스터서버에 kibana 서비스 시작(처음으로 실행 시 포트리슨에 수십 초 걸림)
systemctl start kibana
systemctl status kibana

#로그확인
journalctl -u kibana.service

#마스터서버 kibana접속
http://masterip:5601



#################################
데이터 초기백업
#################################

#데이터노드백업
systemctl stop kibana
systemctl stop elasticsearch

cd ~
tar cvfzp elastic_data_initial.tar.gz /app/elasticsearch/data/nodes/

systemctl start elasticsearch
systemctl start kibana


#################################
데이터 복구
#################################

#모든 노드 서비스 중지
systemctl stop kibana
systemctl stop elasticsearch

rm -rf /var/lib/elasticsearch/nodes
mkdir -p /var/lib/elasticsearch/nodes
chown elasticsearch:elasticsearch /var/lib/elasticsearch/nodes

cd /
tar xvfzp /root/elastic_data_initial.tar.gz 

systemctl start elasticsearch
systemctl start kibana




#################################
1번 마스터서버에서 로그삭제 스케쥴
################################

#crontab 
---------------------------------------------------
###elasticsearch
59 23 * * * /root/mycron/delete_logs.sh
---------------------------------------------------

#srcripts
mkdir -p /root/mycron

vi /root/mycron/delete_logs.sh
---------------------------------------------------
#!/bin/sh

curl -XDELETE http://localhost:9200/logstash-20*
echo `date` : Delete logstash logs  >> /root/mycron/elastic_history.log
---------------------------------------------------

chmod 755 /root/mycron/delete_logs.sh


##################################################################
##################################################################
2번 서버에 LOG STASH 설치(메모리 4g -> 5G로 증설함)
#################################################################
##################################################################

rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch

cat << EOF > /etc/yum.repos.d/logstash.repo 
[logstash-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

sudo yum install -y logstash

systemctl start logstash
systemctl status logstash

#로그확인
tail -f /var/log/logstash/logstash-plain.log


#포트범위 지정 (파일 맨뒤에 추가)
vi /etc/logstash/logstash.yml
-------------------------------------------------------
http.host: "0.0.0.0"
http.port: 9600-9700
-------------------------------------------------------

#/etc/logstash/pipelines.yml 파일 안에서 디폴트 설정 디렉토리가 정의되어 있다. 여기에 확장 *.conf로 만들어 두면
#이정보를 갖고 기동 됨 path.config: "/etc/logstash/conf.d/*.conf"

#설정파일 작성
#filter는 filebeat에서 보내주는 일부 필드를 삭제하기 위함
#grok는 멀티라인으로 통합한 메시지로 부터 날짜/시간을 꺼내서 별도의 필드에 app기준의 시간을 넣는다

cd /etc/logstash/conf.d

vi /etc/logstash/conf.d/logstash-pipeline-5555.conf
-----------------------------------------------------------
input { 
  beats { 
    port => "5555" 
  } 
} 

filter {
  mutate {
    remove_field => [ "beat", "offset", "source", "tags" ]
  }

  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} .*" }
  }
 


  date {
    match => ["apptimestamp", "yyyy:MM:DD HH:mm:ss"]
  }
}

output {
  elasticsearch { hosts => "http://10.10.62.103:9200"
  index => "filebeat-test-log"
  }
}
-----------------------------------------------------------

#그럼 이제 위의 설정을 가지고 실행한다.
#API endpoint는 TCP 9600이고, 리슨포트는 TCP 5555로 나온다
 
systemctl stop logstash

systemctl start logstash

systemctl status logstash

tail -f /var/log/logstash/logstash-plain.log

#구동 정상이면 서비스 자동 등록한다
systemctl enable logstash


#curl -XDELETE http://localhost:9200/filebeat-test-*

 
##################################################################
##################################################################
로그를 보내는 쪽에 Filebeat 설치/실행
#################################################################
##################################################################

#ElasticSecarch서버가 아닌 다른 서버에서 설치&테스트 (권장)
#10.10.64.66 테스트 서버 사용

#설치
rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch

vi /etc/yum.repos.d/elastic.repo
---------------------------------------------------------------
[elastic-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
---------------------------------------------------------------

yum install -y filebeat

#부팅 시 자동실행 설정
sudo chkconfig --add filebeat

#원본 설정파일 백업
cd /etc/filebeat
cp filebeat.yml filebeat.yml.org


#기본설정파일을 수정/작성하여 OS리붓 후에도 자동으로 물고 올라오게 함
vi /etc/filebeat/filebeat.yml
------------------------------------------------------
filebeat:
  prospectors:
  - document_type: log
    encoding: utf-8
    input_type: log
    ignore_older: 24h
    scan_frequency: 5s
    clean_inactive: 48h  
    clean_removed: true    
    paths:
      - /logs/waslog/sds_api_T1CSDSAPIDEV01.log
    multiline.pattern: '^[[0-9]{4}-[0-9]{2}-[0-9]{2}'
    multiline.negate: true
    multiline.match: after
    multiline.timeout: 5s     
output.logstash:
  hosts:
  - 10.10.62.103:5555
  loadbalance: true
------------------------------------------------------



#서비스 실행하면 기본 디렉토리에 설정파일을 가지고 구동

service filebeat status

service filebeat start

service filebeat stop

#기본 로그파일을 보면 어떤 설정과, 어떤 파일을 가지고 동작하는지와 이후 동작을 알 수 있음
tail -f /var/log/filebeat/filebeat


#elasticesearch 도큐먼트 삭제
curl -XDELETE http://localhost:9200/filebeat-test*

#Notice!!!
파일순환 조건이 뭔지 inode가 바뀌는 건지 등 확인 필요함

#파일 라인단위 추적정보 확인
cat /var/lib/filebeat/registry

#레지스트리파일 리셋하려면 서비스를 내린 후에 한다. 서비스 기동 중에 리셋하면 다시 돌아감
service filebeat stop
echo "[]" > /var/lib/filebeat/registry

service filebeat start
service filebeat status









#노트!!!!
VI편집기로 열어서 라인추가하고 저장하면 처음부터 모두 다시 로딩함
단, cat 으로 추가하면 라인 단위로 가져옴;;
-> cat 등은 inode가 바뀌지 않음
-> vi는 inode를 바꿈

 




###############################
후속검토 작업
###############################

-키바나는 @TIMESTMAP를 날짜 인덳을 하고 있는데, apptimestamp 필드로 변경할 것
-아직 인덱스를 하나로 할찌 날짜별로 할지 ...












###############################
기타
###############################




################################################################
LOGSTASH 화면 입력테스트
################################################################

#화면 입력 테스트용 설정파일 작성 (3대 각각 확인)
cat << EOF > /root/test1.conf
input { stdin { } }
output {
  elasticsearch { hosts => ["localhost:9200"] }
  stdout { codec => rubydebug }
}
EOF


#화면 입력 테스트
curl -XDELETE http://localhost:9200/logstash*

/usr/share/logstash/bin/logstash  -f /root/test1.conf


################################################################
LOG STASH 입력테스트2(멀티라인파일입력)
################################################################


#멀티라인 파일 입력 테스트용 설정파일 작성 (3대 각각 확인)
cat << EOF > /root/test2.conf
input {
  file {
    path => "/root/test2.log"
    start_position => "beginning"
    stat_interval => 10
    codec => multiline {
      pattern => "^\s"
      what => "previous"
    }
  }
}

output {
  elasticsearch { hosts => "http://10.10.62.103:9200"
  index => "test2-log"
  }
  stdout { codec => rubydebug }
}
EOF

#멀티라인 테스트용 파일 작성

cat << EOF > /root/test2.log
2018-07-09 01:00:00 row1
  row1-1
  row1-2
  row1-3
2018-07-09 02:00:00 row2
  row2-1
  row2-2
  row2-3
2018-07-09 03:00:00 row3
  row3-1
  row3-2
  row3-3
EOF

#실행(3대 롤링으로 테스트)

/usr/share/logstash/bin/logstash --path.settings=/etc/logstash -f /root/test2.conf

#head에서 확인 후 인덱스 삭제

curl -XDELETE http://localhost:9200/test2*

rm -f /root/test*







